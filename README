AI-Robot
A reinforcement-learning-driven humanoid with Jetson Orin Nano and smart servos
üß† Overview

AI-Robot is an ongoing humanoid robotics project focused on developing dynamic walking through reinforcement learning (RL).
The goal is to create a robot capable of adapting to changing environments, starting with stable locomotion on flat terrain and eventually integrating vision-based object detection and speech models for natural interaction.

This project represents an exploration into combining AI control systems with physical robotics, using RL to handle low-level motor control and a language model as the higher-level ‚Äúbrain‚Äù responsible for decision-making and communication.

‚öôÔ∏è Features (Planned and In Progress)

Dynamic Walking with Reinforcement Learning

RL-based control for adaptive locomotion

Simulation-first training approach before deployment on hardware

Smart Serial Servo Control

Dual-servo setup using Feetech STS3235 and STS3250 actuators

Pulleys with 2:1 gear ratios at select joints for torque optimization

Custom Electronics

PCB with ESP32-S3 microcontroller for servo communication and power management

Jetson Orin Nano as the main compute module running the AI systems

Environmental Awareness (Future)

Integration of a vision system for obstacle perception and terrain recognition

Speech and Interaction (Future)

Onboard LLM to process voice commands and control robot behavior through natural language

üß© System Architecture (In Development)
Component	Function
Jetson Orin Nano	Runs reinforcement learning models and manages high-level control
ESP32-S3 PCB	Interfaces with servos, manages serial bus communication and power
Smart Servos (Feetech STS3235 & STS3250)	Actuators for joints, supporting position feedback and serial daisy-chaining
Pulleys (2:1 ratio)	Increases effective torque at key leg joints
Simulation Environment	Used for RL model training prior to real-world deployment

CAD design (SolidWorks) and PCB layout (Altium Designer) are currently in active development.

üß™ Development Phases

Phase 1 ‚Äî Hardware Integration
Finalize CAD design and PCB for servo control and power distribution.

Phase 2 ‚Äî Reinforcement Learning Simulation
Develop simulation environment for dynamic walking using RL.
(Likely frameworks: PyTorch, custom physics simulation, or Isaac Gym)

Phase 3 ‚Äî Real-World Testing
Transfer trained model to the Jetson Orin Nano for live walking experiments.

Phase 4 ‚Äî Vision and Speech Integration
Add camera input for object detection and LLM for high-level control.

üß† Technical Summary

Programming Language: Python (planned)

Frameworks: TBD (PyTorch or TensorFlow for RL; ROS2 possible integration)

Hardware: Jetson Orin Nano, ESP32-S3, Feetech STS3235/STS3250 smart servos

Design Tools: SolidWorks (mechanical), Altium Designer (PCB)

üöÄ Getting Started

(To be updated as the project matures)

Planned sections:

Installation requirements (JetPack SDK, Python environment, dependencies)

Simulation setup (RL environment)

Model training and deployment instructions

Hardware configuration and servo connection mapping

üìà Future Work

Implement visual SLAM and object detection pipeline

Add voice recognition and LLM-based decision-making

Optimize energy consumption and walking stability

Publish simulation and training environments for community use

üìú License

This project is open source and released under the MIT License.
See the LICENSE
 file for more information.

üë§ Author

Bryan Heddle
Mechatronics & AI Systems Engineering Student ‚Äî Western University
Lead Software Engineer, Western Engineering Mars Rover Team

üí° Acknowledgments

Special thanks to the open-source robotics community for tools, documentation, and inspiration contributing to this project‚Äôs foundation.
